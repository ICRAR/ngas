#
#    ICRAR - International Centre for Radio Astronomy Research
#    (c) UWA - The University of Western Australia, 2012
#    Copyright by UWA (in the framework of the ICRAR)
#    All rights reserved
#
#    This library is free software; you can redistribute it and/or
#    modify it under the terms of the GNU Lesser General Public
#    License as published by the Free Software Foundation; either
#    version 2.1 of the License, or (at your option) any later version.
#
#    This library is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#    Lesser General Public License for more details.
#
#    You should have received a copy of the GNU Lesser General Public
#    License along with this library; if not, write to the Free Software
#    Foundation, Inc., 59 Temple Place, Suite 330, Boston,
#    MA 02111-1307  USA
#
# *****************************************************************************
#
# "@(#) $Id: ngamsCmd_MIRRARCHIVE.py,v 1.6 2010/06/17 14:23:45 awicenec Exp $"
#
# Who       When        What
# --------  ----------  -------------------------------------------------------
# jagonzal  2010/17/01  Created
#
"""
NGAS Command Plug-In, implementing an Archive Command specific for Mirroring

This works in a similar way as the 'standard' ARCHIVE Command, but has been simplified in a few ways:

* No replication to a Replication Volume is carried out.
* Target disks are selected randomly, disregarding the Streams/Storage Set mappings in the configuration. This means
that 'volume load balancing' is provided.
* Archive Proxy Mode is not supported.
* No probing for storage availability is supported.
* In general, less SQL queries are performed and the algorithm is more light-weight.
* crc is computed from the incoming stream
* ngas_files data is 'cloned' from the source file
"""

import logging
import os
import time

from ngamsLib import ngamsDiskInfo, ngamsDbCore
from ngamsLib.ngamsCore import genLog, getFileCreationTime, mvFile, NGAMS_FILE_STATUS_OK, NGAMS_ONLINE_STATE
from . import ngamsCmd_HTTPFETCH
from . import ngamsCmd_RSYNCFETCH
from . import ngamsDAPIMirroring
from . import ngamsFailedDownloadException

logger = logging.getLogger(__name__)


def get_target_volume(ngams_server):
    """
    Get a random target volume with availability
    :param ngams_server: Reference to NG/AMS server class object (ngamsServer)
    :return: Target volume object or None (ngamsDiskInfo | None)
    """
    sql = "select %s from ngas_disks nd " \
          "where completed=0 AND host_id={0} order by available_mb desc" % ngamsDbCore.getNgasDisksCols()
    result = ngams_server.getDb().query2(sql, args=(ngams_server.getHostId(),))
    if not result:
        return None
    else:
        return ngamsDiskInfo.ngamsDiskInfo().unpackSqlResult(result[0])


def update_disk_info(ngams_server, result_dapi, available_space):
    """
    Update the row for the volume hosting the new file
    :param ngams_server: Reference to NG/AMS server class object (ngamsServer)
    :param result_dapi: Result returned from the DAPI (ngamsDapiStatus)
    :param available_space: Remaining space in disk (in MB)
    """
    sql = "update ngas_disks " \
          "set number_of_files=(number_of_files + 1), available_mb = {0}, bytes_stored = (bytes_stored + {1}) " \
          "where disk_id = {2}"
    ngams_server.getDb().query2(sql, args=(available_space, result_dapi.getFileSize(), result_dapi.getDiskId()))


def save_in_staging_file(ngams_server, ngams_config, request_properties, staging_filename, start_byte):
    """
    Save the data ready on the HTTP channel, into the given staging area file
    :param ngams_server: Reference to NG/AMS server class object (ngamsServer)
    :param ngams_config: NG/AMS Configuration (ngamsConfig)
    :param request_properties: NG/AMS Request Properties object (ngamsReqProps)
    :param staging_filename: Staging Area Filename as generated by ngamsHighLevelLib.genStagingFilename() (string)
    :param start_byte: Start byte offset
    :return: File save to archive status information (tuple)
    """
    block_size = ngams_config.getBlockSize()
    fetch_method = 'HTTP'
    if ngams_config.getVal("Mirroring[1].fetch_method"):
        fetch_method = ngams_config.getVal("Mirroring[1].fetch_method")
    if fetch_method == 'RSYNC':
        info = ngamsCmd_RSYNCFETCH.save_to_file(ngams_server, request_properties, staging_filename)
    else:
        info = ngamsCmd_HTTPFETCH.save_to_file(ngams_server, request_properties, staging_filename,
                                               block_size, start_byte)
    return info


def handleCmd(ngams_server, request_properties, http_reference=None):
    """
    Plug-in module handle command function part of plug-in API
    :param ngams_server: Reference to NG/AMS server class object (ngamsServer)
    :param request_properties: NG/AMS Request Properties object (ngamsReqProps)
    :param http_reference: HTTP reference
    """
    if ngams_server.getState() == NGAMS_ONLINE_STATE:
        __handle_command(ngams_server, request_properties)
    else:
        raise ngamsFailedDownloadException.AbortedException("Server is OFFLINE")


def __handle_command(ngams_server, request_properties):
    """
    Handle the mirroring archive command (MIRRARCHIVE)
    :param ngams_server: Reference to NG/AMS server class object (ngamsServer).setState
    :param request_properties: Request Property object to keep track of actions done during the request handling
    (ngamsReqProps).
    """
    # Is this NG/AMS permitted to handle Archive Requests?
    logger.debug("Checking if this NG/AMS permitted to handle Archive Requests?")
    if not ngams_server.getCfg().getAllowArchiveReq():
        error_message = genLog("NGAMS_ER_ILL_REQ", ["Archive"])
        raise Exception(error_message)

    # Generate staging filename
    staging_filename = request_properties.getStagingFilename()
    logger.info("Staging filename is: %s", staging_filename)
    start_byte = 0
    if os.path.exists(staging_filename) == 0:
        logger.debug('Staging file %s is a new file', staging_filename)
    else:
        start_byte = os.path.getsize(staging_filename)
        logger.debug('Staging file %s already exists, requesting resumption of download from byte %d',
                     staging_filename, start_byte)

    # Set reference in request handle object to the read socket
    try:
        # Retrieve file_id and file_version from request proposal
        file_id = request_properties.fileinfo['fileId']
        file_version = request_properties.fileinfo['fileVersion']
        logger.debug("Got file_id=%s and file_version=%s", file_id, file_version)

        # Retrieve file contents (from URL, archive pull, or by storing the body of the HTTP request, archive push)
        logger.info("Saving contents in staging file: %s", staging_filename)
        staging_info = save_in_staging_file(ngams_server, ngams_server.getCfg(), request_properties,
                                            staging_filename, start_byte)
        request_properties.incIoTime(staging_info.rtime)
        request_properties.incIoTime(staging_info.wtime)
        ingest_rate = int(request_properties.getSize() // staging_info.totaltime)
    except (ngamsFailedDownloadException.FailedDownloadException, ngamsFailedDownloadException.PostponeException):
        raise
    except Exception as e:
        if getattr(e, 'errno', 0) == 28:
            # We cannot resume, otherwise the same host will be used next time
            logger.warning("Ran out of disk space during the download to %s. Marking as FAILURE", staging_filename)
            # TODO: automatically mark the volume as completed
            # TODO: try something more sophisticated with the file - other volumes on the same host?
            #  Or at least ARCHIVE in another host avoiding the download of WAN again. This is particularly
            #  important if we just downloaded most of a 300GB file
            raise ngamsFailedDownloadException.FailedDownloadException(e)
        elif request_properties.getBytesReceived() >= 0:
            logger.warning("A fetch has already downloaded data. Marking as TORESUME")
            raise ngamsFailedDownloadException.PostponeException(e)
        else:
            logger.warning("No data has been downloaded yet. Marking as FAILURE")
            raise ngamsFailedDownloadException.FailedDownloadException(e)

    # Invoke DAPI
    logger.info("Invoking DAPI for mirroring")
    result_dapi = ngamsDAPIMirroring.ngams_generic(ngams_server, request_properties)

    # Move file to final destination
    logger.info("Moving file to final destination: %s", result_dapi.getCompleteFilename())
    mtime = mvFile(request_properties.getStagingFilename(), result_dapi.getCompleteFilename())
    request_properties.incIoTime(mtime)

    # Check/generate remaining file info and update in DB
    logger.info("Creating DB entry")
    creation_date = ngams_server.getDb().convertTimeStamp(getFileCreationTime(result_dapi.getCompleteFilename()))
    sql = "update ngas_disks " \
          "set available_mb = available_mb - {0} / (1024 * 1024), bytes_stored = bytes_stored + {1} " \
          "where disk_id = {2}"
    ngams_server.getDb().query2(sql, args=(result_dapi.getFileSize(), result_dapi.getFileSize(),
                                           result_dapi.getDiskId()))

    timestamp = ngams_server.getDb().convertTimeStamp(time.time())
    io_time = int(request_properties.getIoTime() * 1000)
    sql = "insert into ngas_files " \
          "(disk_id, file_name, file_id, " \
          "file_version, format, file_size, " \
          "uncompressed_file_size, compression, ingestion_date, " \
          "{:s}, ".format('file_ignore' if ngams_server.getCfg().getDbUseFileIgnore() else 'ignore') +\
          "checksum, checksum_plugin, file_status, " \
          "creation_date, io_time, ingestion_rate) " \
          "VALUES " \
          "({}, {}, {}, " \
          "{}, {}, {}, " \
          "{}, {},  {}, " \
          "0, " \
          "{}, {}, {}, " \
          "{}, {}, {})"
    args = (str(result_dapi.getDiskId()), str(result_dapi.getRelFilename()), file_id,
            file_version, str(result_dapi.getFormat()), result_dapi.getFileSize(),
            result_dapi.getUncomprSize(), str(result_dapi.getCompression()), timestamp,
            str(staging_info.crc), staging_info.crcname, NGAMS_FILE_STATUS_OK,
            creation_date, io_time, ingest_rate)
    logger.info("Will try to insert the file information: %s / %r", sql, args)
    try:
        ngams_server.getDb().query2(sql, args=args)
    except Exception:
        # this shouldn't happen, but it can. If we rapidly restart a server then there can be some race condition
        # where a thread is already downloading the file and actually finishes it. Meanwhile the main mirroring thread
        # shuts down and sets the status to 'ABORTED'. The next iteration starts mirroring it. before the first thread
        # sets the status to 'SUCCESS'. It happens so rarely that it's easier to work-around than fix properly.
        logger.exception('mirroring error: the file %s has already been registered. Should not have happened, but no damage done.', file_id)

    logger.info("Successfully handled Archive Pull Request for data file with URI: %s",
                request_properties.getSafeFileUri())
    return
